{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install python-dotenv\n",
    "# !pip install dotenv\n",
    "# !pip install PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "ASU_key = os.environ.get(\"ASU_key\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "._AGR-1 AGR-2 and AGR-3 4 Dimensional Change Data Analysis.pdf\n",
      "._Extracting knowledge from data through catalysis informatics.pdf\n",
      "._HUMAN FAILURE EVENT DEPENDENCE WHAT ARE THE LIMITS.pdf\n",
      "._Integration of Human Reliability Analysis Models into the Simulation-Based Framework for the Risk-Informed Safety Margin Characterization Toolkit.pdf\n",
      "._Multi-Unit Dynamic PRA.pdf\n",
      "._MULTIVARIATE STATISTICAL ANALYSIS OF COLEOPTERA SPECTRAL REFLECTA.pdf\n",
      "._Proof-of-Concept Demonstrations for Computation-Based Human Reliability Analysis Modeling Operator Performance During Flooding Scenarios.pdf\n",
      "._simulated human error prop.pdf\n",
      "._Testing_Subtask_Quantification_Assumptions_for_Dyn.pdf\n",
      "._Text-Mining-for-Procedure-Level-Primitives-in-Human-Reliability-Analysis.pdf\n",
      "AGR-1 AGR-2 and AGR-3 4 Dimensional Change Data Analysis.pdf\n",
      "DETERMINATION OF A GENERIC HUMAN ERROR PROBABILITY DISTRIBUTION PART 2 A DYNAMIC SPAR-H EXAMPLE APPLICATION.pdf\n",
      "Extracting knowledge from data through catalysis informatics.pdf\n",
      "FITTING OF FAILURE RATE DATA TO GAMMA-POISSON DISTRIBUTION UTILIZING METHOD OF MOMENTS.pdf\n",
      "HUMAN FAILURE EVENT DEPENDENCE WHAT ARE THE LIMITS.pdf\n",
      "Integration of Human Reliability Analysis Models into the Simulation-Based Framework for the Risk-Informed Safety Margin Characterization Toolkit.pdf\n",
      "Multi-Unit Dynamic PRA.pdf\n",
      "MULTIVARIATE STATISTICAL ANALYSIS OF COLEOPTERA SPECTRAL REFLECTA.pdf\n",
      "Proof-of-Concept Demonstrations for Computation-Based Human Reliability Analysis Modeling Operator Performance During Flooding Scenarios.pdf\n",
      "Quantification of Functional Impact Classification on the Current U.S. Nuclear Fleet.pdf\n",
      "SIMULATED HUMAN ERROR PROBABILITY AND ITS APPLICATION TO DYNAMIC HUMAN FAILURE EVENTS.pdf\n",
      "Testing Subtask Quantification Assumptions for Dynamic Human Reliability Analysis in the SPAR-H Method.pdf\n",
      "Text-Mining-for-Procedure-Level-Primitives-in-Human-Reliability-Analysis.pdf\n",
      "The Virtual Human Reliability Analyst.pdf\n",
      "['AGR-1 AGR-2 and AGR-3 4 Dimensional Change Data Analysis.pdf', 'DETERMINATION OF A GENERIC HUMAN ERROR PROBABILITY DISTRIBUTION PART 2 A DYNAMIC SPAR-H EXAMPLE APPLICATION.pdf', 'Extracting knowledge from data through catalysis informatics.pdf', 'FITTING OF FAILURE RATE DATA TO GAMMA-POISSON DISTRIBUTION UTILIZING METHOD OF MOMENTS.pdf', 'HUMAN FAILURE EVENT DEPENDENCE WHAT ARE THE LIMITS.pdf', 'Integration of Human Reliability Analysis Models into the Simulation-Based Framework for the Risk-Informed Safety Margin Characterization Toolkit.pdf', 'Multi-Unit Dynamic PRA.pdf', 'MULTIVARIATE STATISTICAL ANALYSIS OF COLEOPTERA SPECTRAL REFLECTA.pdf', 'Proof-of-Concept Demonstrations for Computation-Based Human Reliability Analysis Modeling Operator Performance During Flooding Scenarios.pdf', 'Quantification of Functional Impact Classification on the Current U.S. Nuclear Fleet.pdf', 'SIMULATED HUMAN ERROR PROBABILITY AND ITS APPLICATION TO DYNAMIC HUMAN FAILURE EVENTS.pdf', 'Testing Subtask Quantification Assumptions for Dynamic Human Reliability Analysis in the SPAR-H Method.pdf', 'Text-Mining-for-Procedure-Level-Primitives-in-Human-Reliability-Analysis.pdf', 'The Virtual Human Reliability Analyst.pdf']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Specify the folder path\n",
    "folder_path = \"C:/programming_projects/ASU/sarah_pub/\" \n",
    "#### \"\"\"/Users/sarahherberger/Documents/ASU/sarah_pub/\"\"\"\n",
    "\n",
    "# List all files and directories in the folder\n",
    "files = os.listdir(folder_path)\n",
    "\n",
    "# Print the list of files and directories\n",
    "for file in files:\n",
    "    print(file)\n",
    "\n",
    "def remove_if_starts_with(string_list, char):\n",
    "    new_list = []\n",
    "    for string in string_list:\n",
    "        if not string.startswith(char):\n",
    "            new_list.append(string)      # Add original string\n",
    "    return new_list\n",
    "\n",
    "# Example usage:\n",
    "\n",
    "files = remove_if_starts_with(files, \".\")\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' DISCLAIMER This information was prepared as an account of work sponsored by an agency of the U.S. Government. Ne ither the U.S. Government nor any agency thereof, nor any of their employees, makes any warranty, expressed or implied, or assumes any legal liability or responsibility for the accuracy, completeness, or usefulness, of any information, apparatus, product, or process disclosed, or represents that its use would not infringe privately owned rights. References herein to any specific commercial product, process, or service by trade name, tr ade mark, manufacturer, or otherwise, does not necessarily constitute or imply its endorsement, recommendation, or favoring by the U.S. Government or any agency thereof. The views and opinions of authors expressed herein do not necessarily state or reflect those of the U.S. Government or any agency thereof. '"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import PyPDF2\n",
    "import re\n",
    "\n",
    "page_no = 1\n",
    "\n",
    "# Open the PDF in read-binary mode\n",
    "with open(folder_path+files[0], \"rb\") as pdf_file:\n",
    "    # Create a PDF reader object\n",
    "    pdf_reader = PyPDF2.PdfReader(pdf_file)\n",
    "\n",
    "    # Get the number of pages\n",
    "    total_page = len(pdf_reader.pages)\n",
    "\n",
    "    # Extract text from the first page\n",
    "    page = pdf_reader.pages[page_no]\n",
    "    text = page.extract_text()\n",
    "\n",
    "title = re.sub(r'.pdf', ' ', files[1])\n",
    "\n",
    "import re\n",
    "\n",
    "def clean_string(text):\n",
    "    text = re.sub(r'[^A-Za-z0-9., ]', ' ', text)\n",
    "    text = re.sub(r'  ', ' ', text)\n",
    "    text = re.sub(r'  ', ' ', text)\n",
    "    text = re.sub(r'  ', ' ', text)\n",
    "    return text\n",
    "\n",
    "cleaned_string = clean_string(text)\n",
    "cleaned_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1: DISCLAIMER This information was prepared as an account of work sponsored by an agency of the U.S. Government. Ne ither the U.S. Government nor any agency thereof, nor any of their employees, makes any warranty, expressed or implied, or assumes any legal liability or responsibility for the accuracy, completeness, or usefulness, of any information, apparatus, product, or process disclosed, or represents that its use would not infringe privately owned rights. References herein to any specific commercial product, process, or service by trade name, tr ade mark, manufacturer, or otherwise, does not necessarily constitute or imply its endorsement, recommendation, or favoring by the U.S. Government or any agency thereof. The views and opinions of authors expressed herein do not necessarily state or reflect those of the U.S. Government or any agency thereof.\n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "\n",
    "def parse_string_with_overlap(text: str, chunk_length: int, overlap_words: int) -> List[str]:\n",
    "    \"\"\"\n",
    "    Parses a string into chunks with a specified length and word overlap.\n",
    "\n",
    "    Args:\n",
    "        text: The input string.\n",
    "        chunk_length: The desired length of each chunk (in words).\n",
    "        overlap_words: The number of words to overlap between chunks.\n",
    "\n",
    "    Returns:\n",
    "        A list of string chunks.  Returns an empty list if the input is invalid.\n",
    "    \"\"\"\n",
    "\n",
    "    if not isinstance(text, str) or not isinstance(chunk_length, int) or not isinstance(overlap_words, int):\n",
    "        raise TypeError(\"Input types must be: str, int, int\")\n",
    "\n",
    "    if chunk_length <= 0 or overlap_words < 0 or overlap_words >= chunk_length:\n",
    "        raise ValueError(\"chunk_length must be > 0, overlap_words must be >= 0 and < chunk_length\")\n",
    "\n",
    "\n",
    "    words = text.split()\n",
    "    num_words = len(words)\n",
    "\n",
    "    if num_words == 0:  # Handle empty string\n",
    "        return []\n",
    "\n",
    "    chunks = []\n",
    "    start_index = 0\n",
    "\n",
    "    while start_index < num_words:\n",
    "        end_index = min(start_index + chunk_length, num_words)  # Don't exceed string length\n",
    "        chunk = \" \".join(words[start_index:end_index])\n",
    "        chunks.append(chunk)\n",
    "\n",
    "        start_index += (chunk_length - overlap_words)  # Move starting point\n",
    "\n",
    "    return chunks\n",
    "\n",
    "word_count = len(cleaned_string.split())\n",
    "\n",
    "if word_count > 1000:\n",
    "    try:\n",
    "        chunks = parse_string_with_overlap(cleaned_string, int(word_count/4), 15)\n",
    "    except ValueError as e:\n",
    "        chunks = cleaned_string\n",
    "        print(f\"Error: {e}\")\n",
    "if word_count <= 1000:\n",
    "    chunks = parse_string_with_overlap(cleaned_string, word_count, 0)\n",
    "\n",
    "for i, chunk in enumerate(chunks):\n",
    "    print(f\"Chunk {i+1}: {chunk}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result: Introduction\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "key = ASU_key\n",
    "\n",
    "api_url = 'https://api-dev-poc.aiml.asu.edu/queryV2'\n",
    "bearer_token = key\n",
    "json_payload = {\n",
    "    \"query\": \"what part of a document is the following text from in a academic paper {cleaned_string}? only respond with the section type, no other text.\".format(cleaned_string=cleaned_string),\n",
    "    \"model_provider\": \"gcp-deepmind\",\n",
    "    \"model_name\": \"geminiflash1_5\",\n",
    "}\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {bearer_token}\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "try:\n",
    "    response = requests.post(api_url, headers=headers, json=json_payload)\n",
    "    response.raise_for_status()\n",
    "    result_document_section = response.json().get(\"response\")\n",
    "    print(\"result:\", result_document_section)\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(f\"API request error: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"Unexpected error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "given that the following text from the document Extracting knowledge from data through catalysis informatics.pdf on page 1 of total page 53: Extracting knowledge from data through catalysis informatics Andrew J. Medford, ,yM. Ross Kunz,zSarah M. Ewing,zTammie Borders,zand Rebecca Fushimi ,z, ySchool of Chemical Biomolecular Engineering, Georgia Institute of Technology, Atlanta, GA, USA zBiological and Chemical Processing Department, Energy and Environmental Science and Technology, Idaho National Laboratory, PO Box 1625, Idaho Falls, ID 83415, USA Center for Advanced Energy Studies, 995 University Boulevard, Idaho Falls, ID 83401, USA E mail andrew.medford chbe.gatech.edu rebecca.fushimi inl.gov Abstract Catalysis informatics is a distinct sub eld that lies at the intersection of cheminformat ics and materials informatics, but with unique challenges arising from the dynamic, surface sensitive, and multi scale nature of heteroge neous catalysis. The ideas behind catalysis in formatics can be traced back decades, but the eld is only recently emerging due to advances in data infrastructure, statistics, machine learn ing, and computational methods. In this work we review the eld from early works on expert systems and knowledge engines to more recent approaches utilizing machine learning and un certainty quanti cation. The data information knowledge hierarchy is introduced and used to classify various developments. The chemical master equation and micro kinetic models are proposed as a quantitative representation of catalysis knowledge, which can be used to gen erate explanative and predictive hypotheses for the understanding and discovery of catalytic materials. We discuss future prospects for the eld, including improved quantitative coupling of experiment theory, advanced micro kinetic models, and the development of open source software tools. Ultimately, integration of exist ing chemical and physical models with emerg ing statistical and computational tools presents a promising route toward the automated de sign, discovery, and optimization of heteroge neous catalytic processes. 1 Introduction The term catalysis informatics has been used increasingly in the eld of heterogeneous catal ysis since as early as 2001,1yet there is no clear de nition of the phrase. The term in formatics appears relatively few times in the catalysis literature,1 10with a few works re ferring to catalysis informatics speci cally in several rather di erent contexts.1,4,7 10In this work we de ne catalysis informatics as the extraction of knowledge from information via the design, representation and organization of data sets and the application of data min ing and analysis tools to accelerate the discov ery and understanding of heterogeneous cat alytic materials. This de nition includes many of the machine learning techniques that have recently been applied to the eld of cataly sis,7,10 21but the focus is on the extraction of actionable and interpretable knowledge, rather than the identi cation of patterns or accelera tion of methods.22We limit the scope to hetero 1\n",
      "\n",
      " \n",
      "what are some good questions to ask about the Abstract section? Please respond with question and answers for 5 questions.\n",
      "\n",
      "the questions need to be well defined. Do not use the phrase \"in the paper\" you can say Extracting knowledge from data through catalysis informatics . Answers need to be at least 2 sentences long.\n",
      "\n",
      "Please use the following format for the response:\n",
      "\n",
      "**Question 1:**\n",
      "**Answer 1:**\n",
      "\n",
      "**Question 2:**\n",
      "**Answer 2:**\n",
      "\n",
      "**Question 3:**\n",
      "**Answer 3:**\n",
      "\n",
      "**Question 4:**\n",
      "**Answer 4:**\n",
      "\n",
      "**Question 5:**\n",
      "**Answer 5:**\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"given that the following text from the document {files} on page {page_no} of total page {total_page}: {cleaned_string}\\n\\n \n",
    "what are some good questions to ask about the {section} section? Please respond with question and answers for 5 questions.\n",
    "\n",
    "the questions need to be well defined. Do not use the phrase \"in the paper\" you can say {title}. Answers need to be at least 2 sentences long.\n",
    "\n",
    "Please use the following format for the response:\n",
    "\n",
    "**Question 1:**\n",
    "**Answer 1:**\n",
    "\n",
    "**Question 2:**\n",
    "**Answer 2:**\n",
    "\n",
    "**Question 3:**\n",
    "**Answer 3:**\n",
    "\n",
    "**Question 4:**\n",
    "**Answer 4:**\n",
    "\n",
    "**Question 5:**\n",
    "**Answer 5:**\n",
    "\"\"\".format(files=files[1],\n",
    "                                                                                                                                                                                                                           page_no = page_no,\n",
    "                                                                                                                                                                                                                           total_page = total_page,\n",
    "                                                                                                                                                                                                                           cleaned_string=cleaned_string,\n",
    "                                                                                                                                                                                                                           section=result_document_section,\n",
    "                                                                                                                                                                                                                           title=title)\n",
    "print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result: Here are 5 questions and answers based on the Abstract of \"Extracting knowledge from data through catalysis informatics\":\n",
      "\n",
      "**Question 1:** What are the unique challenges that catalysis informatics faces compared to other informatics disciplines? \n",
      "\n",
      "**Answer 1:**  Catalysis informatics faces challenges due to the complex and dynamic nature of heterogeneous catalysis. Unlike typical informatics, this discipline deals with systems where surface sensitivity, multi-scale phenomena, and dynamic interactions are crucial. \n",
      "\n",
      "**Question 2:**  How does the concept of \"data information knowledge hierarchy\" contribute to understanding catalysis informatics?\n",
      "\n",
      "**Answer 2:** The hierarchy helps categorize different advancements in the field. It allows researchers to understand how raw data is transformed through analysis into meaningful information, ultimately leading to actionable knowledge about catalytic materials.\n",
      "\n",
      "**Question 3:** What are the key elements of the proposed quantitative representation of catalysis knowledge?\n",
      "\n",
      "**Answer 3:** The  \"chemical master equation\" and \"micro kinetic models\" are proposed as a quantitative representation of catalysis knowledge. These models can be used to generate hypotheses for understanding and discovering new catalytic materials. \n",
      "\n",
      "**Question 4:**  What are some of the future prospects for the development of catalysis informatics?\n",
      "\n",
      "**Answer 4:** The authors highlight the potential of integrating chemical and physical models with statistical and computational tools. This approach could lead to automated design, discovery, and optimization of heterogeneous catalytic processes.\n",
      "\n",
      "**Question 5:** How does the definition of catalysis informatics in this paper differ from previous definitions?\n",
      "\n",
      "**Answer 5:** The paper defines catalysis informatics as the extraction of actionable and interpretable knowledge from data, focusing on understanding and discovering new catalytic materials. This definition emphasizes knowledge extraction, distinct from simply identifying patterns or accelerating methods.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "api_url = 'https://api-dev-poc.aiml.asu.edu/queryV2'\n",
    "bearer_token = key\n",
    "json_payload = {\n",
    "    \"query\": query,\n",
    "    \"model_provider\": \"gcp-deepmind\",\n",
    "    \"model_name\": \"geminiflash1_5\",\n",
    "}\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {bearer_token}\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "try:\n",
    "    response = requests.post(api_url, headers=headers, json=json_payload)\n",
    "    response.raise_for_status()\n",
    "    result = response.json().get(\"response\")\n",
    "    print(\"result:\", result)\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(f\"API request error: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"Unexpected error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "parts = result.split(\"**\")  # Split the string at comma\n",
    "print(parts[2])\n",
    "\n",
    "parts_no = [[2, 4], [6, 8], [10, 12], [14, 16], [18, 20]]\n",
    "df_out = pd.DataFrame([])\n",
    "\n",
    "for i in range(0, 5):\n",
    "    pt1 = parts_no[i][0]\n",
    "    pt2 = parts_no[i][1]\n",
    "\n",
    "    Q1 = pd.DataFrame(data={'section':[result_document_section],\n",
    "                            'title':[title],\n",
    "                            'file_name':[files[1]],\n",
    "                            'document_type':['academic paper'],\n",
    "                            'subject':['science, chemistry, materials science'],\n",
    "                            'page': [page_no], \n",
    "                            'total_pages': [total_page],\n",
    "                            'context': [cleaned_string],\n",
    "                            'question':[parts[pt1]],\n",
    "                            'answer':[parts[pt2]]\n",
    "                            })\n",
    "    df_out = pd.concat([Q1, df_out], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>section</th>\n",
       "      <th>title</th>\n",
       "      <th>file_name</th>\n",
       "      <th>document_type</th>\n",
       "      <th>subject</th>\n",
       "      <th>page</th>\n",
       "      <th>total_pages</th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abstract</td>\n",
       "      <td>Extracting knowledge from data through catalys...</td>\n",
       "      <td>Extracting knowledge from data through catalys...</td>\n",
       "      <td>academic paper</td>\n",
       "      <td>science, chemistry, materials science</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>Extracting knowledge from data through catalys...</td>\n",
       "      <td>What is the purpose of including a disclaime...</td>\n",
       "      <td>The disclaimer serves several purposes. It pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Abstract</td>\n",
       "      <td>Extracting knowledge from data through catalys...</td>\n",
       "      <td>Extracting knowledge from data through catalys...</td>\n",
       "      <td>academic paper</td>\n",
       "      <td>science, chemistry, materials science</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>Extracting knowledge from data through catalys...</td>\n",
       "      <td>Does the disclaimer suggest that the views e...</td>\n",
       "      <td>No, the disclaimer explicitly states that the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Abstract</td>\n",
       "      <td>Extracting knowledge from data through catalys...</td>\n",
       "      <td>Extracting knowledge from data through catalys...</td>\n",
       "      <td>academic paper</td>\n",
       "      <td>science, chemistry, materials science</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>Extracting knowledge from data through catalys...</td>\n",
       "      <td>What kind of liability does the U.S. Governme...</td>\n",
       "      <td>The disclaimer states that neither the U.S. G...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Abstract</td>\n",
       "      <td>Extracting knowledge from data through catalys...</td>\n",
       "      <td>Extracting knowledge from data through catalys...</td>\n",
       "      <td>academic paper</td>\n",
       "      <td>science, chemistry, materials science</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>Extracting knowledge from data through catalys...</td>\n",
       "      <td>What specific type of document is \"Extracting...</td>\n",
       "      <td>The disclaimer clarifies that the document is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Abstract</td>\n",
       "      <td>Extracting knowledge from data through catalys...</td>\n",
       "      <td>Extracting knowledge from data through catalys...</td>\n",
       "      <td>academic paper</td>\n",
       "      <td>science, chemistry, materials science</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>Extracting knowledge from data through catalys...</td>\n",
       "      <td>Who is the sponsor of the work described in \"...</td>\n",
       "      <td>The disclaimer states that the work was prepa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    section                                              title  \\\n",
       "0  Abstract  Extracting knowledge from data through catalys...   \n",
       "1  Abstract  Extracting knowledge from data through catalys...   \n",
       "2  Abstract  Extracting knowledge from data through catalys...   \n",
       "3  Abstract  Extracting knowledge from data through catalys...   \n",
       "4  Abstract  Extracting knowledge from data through catalys...   \n",
       "\n",
       "                                           file_name   document_type  \\\n",
       "0  Extracting knowledge from data through catalys...  academic paper   \n",
       "1  Extracting knowledge from data through catalys...  academic paper   \n",
       "2  Extracting knowledge from data through catalys...  academic paper   \n",
       "3  Extracting knowledge from data through catalys...  academic paper   \n",
       "4  Extracting knowledge from data through catalys...  academic paper   \n",
       "\n",
       "                                 subject  page  total_pages  \\\n",
       "0  science, chemistry, materials science     1           53   \n",
       "1  science, chemistry, materials science     1           53   \n",
       "2  science, chemistry, materials science     1           53   \n",
       "3  science, chemistry, materials science     1           53   \n",
       "4  science, chemistry, materials science     1           53   \n",
       "\n",
       "                                             context  \\\n",
       "0  Extracting knowledge from data through catalys...   \n",
       "1  Extracting knowledge from data through catalys...   \n",
       "2  Extracting knowledge from data through catalys...   \n",
       "3  Extracting knowledge from data through catalys...   \n",
       "4  Extracting knowledge from data through catalys...   \n",
       "\n",
       "                                            question  \\\n",
       "0    What is the purpose of including a disclaime...   \n",
       "1    Does the disclaimer suggest that the views e...   \n",
       "2   What kind of liability does the U.S. Governme...   \n",
       "3   What specific type of document is \"Extracting...   \n",
       "4   Who is the sponsor of the work described in \"...   \n",
       "\n",
       "                                              answer  \n",
       "0   The disclaimer serves several purposes. It pr...  \n",
       "1   No, the disclaimer explicitly states that the...  \n",
       "2   The disclaimer states that neither the U.S. G...  \n",
       "3   The disclaimer clarifies that the document is...  \n",
       "4   The disclaimer states that the work was prepa...  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " What are the unique challenges that catalysis informatics faces compared to other informatics disciplines? \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "parts = result.split(\"**\")  # Split the string at comma\n",
    "print(parts[2])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
