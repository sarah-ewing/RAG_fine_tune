{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4301b4c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting python-Levenshtein\n",
      "  Downloading python_levenshtein-0.27.1-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting Levenshtein==0.27.1 (from python-Levenshtein)\n",
      "  Downloading levenshtein-0.27.1-cp312-cp312-win_amd64.whl.metadata (3.6 kB)\n",
      "Collecting rapidfuzz<4.0.0,>=3.9.0 (from Levenshtein==0.27.1->python-Levenshtein)\n",
      "  Downloading rapidfuzz-3.13.0-cp312-cp312-win_amd64.whl.metadata (12 kB)\n",
      "Downloading python_levenshtein-0.27.1-py3-none-any.whl (9.4 kB)\n",
      "Downloading levenshtein-0.27.1-cp312-cp312-win_amd64.whl (100 kB)\n",
      "Downloading rapidfuzz-3.13.0-cp312-cp312-win_amd64.whl (1.6 MB)\n",
      "   ---------------------------------------- 0.0/1.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.6/1.6 MB 17.1 MB/s eta 0:00:00\n",
      "Installing collected packages: rapidfuzz, Levenshtein, python-Levenshtein\n",
      "Successfully installed Levenshtein-0.27.1 python-Levenshtein-0.27.1 rapidfuzz-3.13.0\n"
     ]
    }
   ],
   "source": [
    "# !pip install fuzzywuzzy\n",
    "# !pip install python-Levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ff7d63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import evaluate\n",
    "\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    message=\"Using the latest cached version of the module.*\",\n",
    "    category=UserWarning  # Or possibly a more specific warning category\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b087121",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['title', 'url', 'document_type', 'chunked_word_count',\n",
       "       'orig_word_count', 'context', 'question', 'answer', 'filename'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "ASU_key = os.environ.get(\"ASU_key\") \n",
    "endpoint_url = os.environ.get(\"endpoint_url\") \n",
    "\n",
    "import requests\n",
    "start_ii = 0\n",
    "\n",
    "import functions as fun\n",
    "\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {ASU_key}\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "#################################   \n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(r'C:\\\\programming_projects\\\\RAG_fine_tune\\\\RAG_pipeline_ASU_website\\\\data\\\\silver_data_4_16_2025.csv',\n",
    "                 dtype={'title': 'str', \n",
    "                        'url': 'str', \n",
    "                        'document_type': 'str',\n",
    "                        'chunked_word_count':'int64',\n",
    "                        'orig_word_count':'int64',\n",
    "                        'contex':'str',\n",
    "                        'question':'str',\n",
    "                        'answer':'str',\n",
    "                        'filename':'str',\n",
    "                        'section':'str'})\n",
    "df = df.reset_index(drop=True)\n",
    "df.rename( columns={'contex': 'context'},inplace=True)\n",
    "\n",
    "df['question'] = df['question'].str.replace('\\n', ' ')\n",
    "df['answer'] = df['answer'].str.replace('\\n', ' ')\n",
    "df['context'] = df['context'].str.replace('\\n', ' ')\n",
    "\n",
    "# Identify the rows where 'context' is numeric and remove them\n",
    "numeric_context_mask = pd.to_numeric(df['context'], errors='coerce').notna()\n",
    "# Filter out those rows\n",
    "df = df[~numeric_context_mask].copy()\n",
    "\n",
    "df['similarity_score'] = 0.0\n",
    "df['NLTK_bleu'] = 0.0\n",
    "df['sacrebleu_bleu'] = 0.0\n",
    "df['Cosine'] = 0.0\n",
    "df['rouge1'] = 0.0\n",
    "df['rouge2'] = 0.0\n",
    "df['rougeL'] = 0.0\n",
    "df['rougeLsum'] = 0.0\n",
    "df['sBURT'] = 0.0\n",
    "\n",
    "df['ragas_bleu'] = 0.0\n",
    "df['ragas_precision_reference'] = 0.0\n",
    "df['ragas_faith'] = 0.0\n",
    "df['ragas_fact'] = 0.0\n",
    "df['regas_sem_sim'] = 0.0\n",
    "df['regas_rogue'] = 0.0\n",
    "\n",
    "df = df[['title', 'url', 'document_type', 'chunked_word_count', 'orig_word_count', 'context', 'question', 'answer', 'filename']]\n",
    "df.shape, df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aaa30797",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>document_type</th>\n",
       "      <th>chunked_word_count</th>\n",
       "      <th>orig_word_count</th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ASU Library Research Data Repository</td>\n",
       "      <td>https://dataverse.asu.edu/dataverse/asulibrary...</td>\n",
       "      <td>web page</td>\n",
       "      <td>500</td>\n",
       "      <td>814</td>\n",
       "      <td>Apr 19 2024 Physical and Computational Thermal...</td>\n",
       "      <td>Besides parking infrastructure, what other res...</td>\n",
       "      <td>Post fire debris flow risk and roadway vulnera...</td>\n",
       "      <td>processed_data_thread_10_start_115100_500_rows...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ASU Library Research Data Repository</td>\n",
       "      <td>https://dataverse.asu.edu/dataverse/asulibrary...</td>\n",
       "      <td>web page</td>\n",
       "      <td>500</td>\n",
       "      <td>814</td>\n",
       "      <td>Apr 19 2024 Physical and Computational Thermal...</td>\n",
       "      <td>Besides parking infrastructure, what other res...</td>\n",
       "      <td>Another research area is neuroscience, specifi...</td>\n",
       "      <td>processed_data_thread_10_start_115100_500_rows...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ASU Library Research Data Repository</td>\n",
       "      <td>https://dataverse.asu.edu/dataverse/asulibrary...</td>\n",
       "      <td>web page</td>\n",
       "      <td>500</td>\n",
       "      <td>814</td>\n",
       "      <td>Apr 19 2024 Physical and Computational Thermal...</td>\n",
       "      <td>Besides parking infrastructure, what other res...</td>\n",
       "      <td>One dataset focuses on characterizing human ex...</td>\n",
       "      <td>processed_data_thread_10_start_115100_500_rows...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ASU Library Research Data Repository</td>\n",
       "      <td>https://dataverse.asu.edu/dataverse/asulibrary...</td>\n",
       "      <td>web page</td>\n",
       "      <td>500</td>\n",
       "      <td>814</td>\n",
       "      <td>Apr 19 2024 Physical and Computational Thermal...</td>\n",
       "      <td>What are some of the methodologies used to cre...</td>\n",
       "      <td>The post fire debris flow risk assessment uses...</td>\n",
       "      <td>processed_data_thread_10_start_115100_500_rows...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ASU Library Research Data Repository</td>\n",
       "      <td>https://dataverse.asu.edu/dataverse/asulibrary...</td>\n",
       "      <td>web page</td>\n",
       "      <td>500</td>\n",
       "      <td>814</td>\n",
       "      <td>Apr 19 2024 Physical and Computational Thermal...</td>\n",
       "      <td>What are some of the methodologies used to cre...</td>\n",
       "      <td>In creating the parking inventory for Phoenix,...</td>\n",
       "      <td>processed_data_thread_10_start_115100_500_rows...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  title  \\\n",
       "0  ASU Library Research Data Repository   \n",
       "1  ASU Library Research Data Repository   \n",
       "2  ASU Library Research Data Repository   \n",
       "3  ASU Library Research Data Repository   \n",
       "4  ASU Library Research Data Repository   \n",
       "\n",
       "                                                 url document_type  \\\n",
       "0  https://dataverse.asu.edu/dataverse/asulibrary...      web page   \n",
       "1  https://dataverse.asu.edu/dataverse/asulibrary...      web page   \n",
       "2  https://dataverse.asu.edu/dataverse/asulibrary...      web page   \n",
       "3  https://dataverse.asu.edu/dataverse/asulibrary...      web page   \n",
       "4  https://dataverse.asu.edu/dataverse/asulibrary...      web page   \n",
       "\n",
       "   chunked_word_count  orig_word_count  \\\n",
       "0                 500              814   \n",
       "1                 500              814   \n",
       "2                 500              814   \n",
       "3                 500              814   \n",
       "4                 500              814   \n",
       "\n",
       "                                             context  \\\n",
       "0  Apr 19 2024 Physical and Computational Thermal...   \n",
       "1  Apr 19 2024 Physical and Computational Thermal...   \n",
       "2  Apr 19 2024 Physical and Computational Thermal...   \n",
       "3  Apr 19 2024 Physical and Computational Thermal...   \n",
       "4  Apr 19 2024 Physical and Computational Thermal...   \n",
       "\n",
       "                                            question  \\\n",
       "0  Besides parking infrastructure, what other res...   \n",
       "1  Besides parking infrastructure, what other res...   \n",
       "2  Besides parking infrastructure, what other res...   \n",
       "3  What are some of the methodologies used to cre...   \n",
       "4  What are some of the methodologies used to cre...   \n",
       "\n",
       "                                              answer  \\\n",
       "0  Post fire debris flow risk and roadway vulnera...   \n",
       "1  Another research area is neuroscience, specifi...   \n",
       "2  One dataset focuses on characterizing human ex...   \n",
       "3  The post fire debris flow risk assessment uses...   \n",
       "4  In creating the parking inventory for Phoenix,...   \n",
       "\n",
       "                                            filename  \n",
       "0  processed_data_thread_10_start_115100_500_rows...  \n",
       "1  processed_data_thread_10_start_115100_500_rows...  \n",
       "2  processed_data_thread_10_start_115100_500_rows...  \n",
       "3  processed_data_thread_10_start_115100_500_rows...  \n",
       "4  processed_data_thread_10_start_115100_500_rows...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "790905eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title                         object\n",
       "url                           object\n",
       "document_type                 object\n",
       "chunked_word_count             int64\n",
       "orig_word_count                int64\n",
       "context                       object\n",
       "question                      object\n",
       "answer                        object\n",
       "filename                      object\n",
       "similarity_score             float64\n",
       "Cosine                       float64\n",
       "sacrebleu_bleu                object\n",
       "NLTK_bleu                    float64\n",
       "chrf                          object\n",
       "sBURT                        float32\n",
       "rouge1                       float64\n",
       "rouge2                       float64\n",
       "rougeL                       float64\n",
       "rougeLsum                    float64\n",
       "ragas_bleu                   float64\n",
       "ragas_precision_reference    float64\n",
       "ragas_faith                  float64\n",
       "ragas_fact                   float64\n",
       "regas_sem_sim                float64\n",
       "regas_rogue                  float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "606db3c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], Name: context, dtype: object)\n"
     ]
    }
   ],
   "source": [
    "# print(df[pd.to_numeric(df['answer'], errors='coerce').notna()])\n",
    "print(df['context'][pd.to_numeric(df['context'], errors='coerce').notna()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f595c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-17 14:07:11.082065\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "print(datetime.datetime.now())\n",
    "df['similarity_score'] = df.apply(lambda row: fun.calculate_fuzzy_similarity(str(row['answer']), str(row['context'])), axis=1)\n",
    "print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c7a6d50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "result: {'metric': 'bleuscore', 'score': 0.16620689217205012}\n",
      "result: {'metric': 'context_precision_with_reference', 'score': 0.9999999999}\n",
      "result: {'metric': 'faithfulness', 'score': 1.0}\n",
      "result: {'metric': 'factual_correctness', 'score': 0.3}\n",
      "result: {'metric': 'semantic_similarity', 'score': 0.7937536069746418}\n",
      "result: {'metric': 'rouge_score', 'score': 0.08775137111517366}\n",
      "1\n",
      "result: {'metric': 'bleuscore', 'score': 0.21651956746181064}\n",
      "result: {'metric': 'context_precision_with_reference', 'score': 0.9999999999}\n",
      "result: {'metric': 'faithfulness', 'score': 1.0}\n",
      "result: {'metric': 'factual_correctness', 'score': 0.27}\n",
      "result: {'metric': 'semantic_similarity', 'score': 0.7662673753266493}\n",
      "result: {'metric': 'rouge_score', 'score': 0.058715596330275226}\n"
     ]
    }
   ],
   "source": [
    "#############################################################################\n",
    "\n",
    "if start_ii > 0:\n",
    "    df = pd.read_csv('C:\\\\programming_projects\\\\RAG_fine_tune\\\\RAG_pipeline_ASU_website\\\\data\\\\qa_results_RAGAS_evaluated.csv')\n",
    "\n",
    "for ii in range(start_ii, 2): #len(df['question'])):\n",
    "    print(ii)\n",
    "\n",
    "    questiony = df['question'].iloc[ii]\n",
    "    answery = df['answer'].iloc[ii]\n",
    "    contexty = df['context'].iloc[ii]\n",
    "\n",
    "\n",
    "    ###########################################################################\n",
    "    #### old school\n",
    "    ###########################################################################\n",
    "    similarity_score = fun.calculate_fuzzy_similarity(answery, contexty)\n",
    "    df.loc[ii, 'similarity_score'] = similarity_score\n",
    "    # print(f\"Fuzzy Similarity Score: {similarity_score}\")\n",
    "\n",
    "    tfidf_similarity = fun.calculate_tfidf_cosine_similarity(answery, contexty)\n",
    "    df.loc[ii, 'Cosine'] = tfidf_similarity\n",
    "    # print(f\"TF-IDF Cosine Similarity: {tfidf_similarity:.2f}\")\n",
    "\n",
    "    ## sacrebleu bleu\n",
    "    df.loc[ii, 'sacrebleu_bleu'] = fun.BLEU_SIM(A = answery, B =  contexty)\n",
    "\n",
    "    ## NLTK bleu\n",
    "    bleu_score = fun.calculate_bleu_score(answery, contexty)\n",
    "    df.loc[ii, 'NLTK_bleu'] = bleu_score\n",
    "    # print(f\"BLEU Score: {bleu_score:.2f}\")\n",
    "\n",
    "    ## charcter level f score\n",
    "    df.loc[ii, 'chrf'] = fun.FSCORE_SIM(A = answery, B =  contexty)\n",
    "\n",
    "    ## sBURT\n",
    "    df.loc[ii, 'sBURT'] = fun.sBERT(tokens1 = answery, tokens2 = contexty)\n",
    "\n",
    "    ## rogue calcs\n",
    "    results = fun.rouge_SIM(A =  contexty, B = answery)\n",
    "\n",
    "    df.loc[ii, 'rouge1'] = results['rouge1']\n",
    "    df.loc[ii, 'rouge2'] = results['rouge2']\n",
    "    df.loc[ii, 'rougeL'] = results['rougeL']\n",
    "    df.loc[ii, 'rougeLsum'] = results['rougeLsum']\n",
    "    \n",
    "    ###########################################################################\n",
    "    #### RAGAS\n",
    "    ###########################################################################\n",
    "\n",
    "    ##################################\n",
    "    ### Bluescore\n",
    "    payload_blue = {\n",
    "        \"model_provider\": \"openai\",\n",
    "        \"model_name\": \"gpt-4o\",\n",
    "        \"metric\": \"bleuscore\",\n",
    "        \"parameters\": {\n",
    "            \"user_input\": questiony,\n",
    "            \"response\": answery,\n",
    "            \"reference\": contexty,\n",
    "        }\n",
    "    }\n",
    "    try:\n",
    "        response = requests.post(endpoint_url, headers=headers, json=payload_blue)\n",
    "        response.raise_for_status()\n",
    "        result = response.json()\n",
    "        print(\"result:\", result)\n",
    "        #### SAVE BLEU score\n",
    "        df.loc[ii,'ragas_bleu'] = result['score']\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"API request error: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error: {e}\")\n",
    "\n",
    "    ##################################\n",
    "    ## Context Precision With Reference\n",
    "    payload_precision_reference = {\n",
    "        \"model_provider\": \"openai\",\n",
    "        \"model_name\": \"gpt-4o\",\n",
    "        \"metric\": \"context_precision_with_reference\",\n",
    "        \"parameters\": {\n",
    "            \"user_input\": questiony,\n",
    "            \"reference\": answery,\n",
    "            \"retrieved_contexts\": [\n",
    "                contexty,\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "    try:\n",
    "        response = requests.post(endpoint_url, headers=headers, json=payload_precision_reference)\n",
    "        response.raise_for_status()\n",
    "        result = response.json()\n",
    "        print(\"result:\", result)\n",
    "        #### SAVE Precision With Reference score\n",
    "        df.loc[ii,'ragas_precision_reference'] = result['score']\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"API request error: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error: {e}\")\n",
    "\n",
    "    #################################\n",
    "    ### RAGAS Faithfulness\n",
    "    payload_ragas_faith = {\n",
    "        \"model_provider\": \"openai\",\n",
    "        \"model_name\": \"gpt-4o\",\n",
    "        \"metric\": \"faithfulness\",\n",
    "        \"parameters\": {\n",
    "            \"user_input\": questiony,\n",
    "            \"response\": answery,\n",
    "            \"retrieved_contexts\": [\n",
    "                contexty,\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "    try:\n",
    "        response = requests.post(endpoint_url, headers=headers, json=payload_ragas_faith)\n",
    "        response.raise_for_status()\n",
    "        result = response.json()\n",
    "        print(\"result:\", result)\n",
    "        #### SAVE RAGAS Faithfulness score\n",
    "        df.loc[ii,'ragas_faith'] = result['score']\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"API request error: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error: {e}\")\n",
    "\n",
    "    ##################################\n",
    "    ### Factual correctness\n",
    "    # print(\"Factual Correctness\")\n",
    "    payload_fact = {\n",
    "        \"model_provider\": \"openai\",\n",
    "        \"model_name\": \"gpt-4o\",\n",
    "        \"metric\": \"factual_correctness\",\n",
    "        \"parameters\": {\n",
    "            \"response\": str(answery),\n",
    "            \"reference\": str(contexty)\n",
    "        }\n",
    "    }\n",
    "    try:\n",
    "        response = requests.post(endpoint_url, headers=headers, json=payload_fact)\n",
    "        response.raise_for_status()\n",
    "        result = response.json()\n",
    "        print(\"result:\", result)\n",
    "        #### SAVE Factual correctness score\n",
    "        df.loc[ii,'ragas_fact'] = result['score']\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"API request error: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error: {e}\")\n",
    "\n",
    "    ##################################\n",
    "    ### Semantic similarity\n",
    "    payload_sem_sim = {\n",
    "        \"model_provider\": \"openai\",\n",
    "        \"model_name\": \"gpt-4o\",\n",
    "        \"metric\": \"semantic_similarity\",\n",
    "        \"parameters\": {\n",
    "            \"response\": answery,\n",
    "            \"reference\": contexty\n",
    "        }\n",
    "    }\n",
    "    try:\n",
    "        response = requests.post(endpoint_url, headers=headers, json=payload_sem_sim)\n",
    "        response.raise_for_status()\n",
    "        result = response.json()\n",
    "        print(\"result:\", result)\n",
    "        #### SAVE Factual correctness score\n",
    "        df.loc[ii,'regas_sem_sim'] = result['score']\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"API request error: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error: {e}\")\n",
    "\n",
    "    ##################################\n",
    "    ### Rouge score\n",
    "    payload_rogue = {\n",
    "        \"model_provider\": \"openai\",\n",
    "        \"model_name\": \"gpt-4o\",\n",
    "        \"metric\": \"rouge_score\",\n",
    "        \"parameters\": {\n",
    "            \"response\": answery,\n",
    "            \"reference\": contexty\n",
    "        }\n",
    "    }\n",
    "    try:\n",
    "        response = requests.post(endpoint_url, headers=headers, json=payload_rogue)\n",
    "        response.raise_for_status()\n",
    "        result = response.json()\n",
    "        print(\"result:\", result)\n",
    "        #### SAVE Factual correctness score\n",
    "        df.loc[ii,'regas_rogue'] = result['score']\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"API request error: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error: {e}\")\n",
    "\n",
    "\n",
    "    df.to_csv('C:\\\\programming_projects\\\\RAG_fine_tune\\\\RAG_pipeline_ASU_website\\\\data\\\\5_context_question_answer.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28aeb33f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>similarity_score</th>\n",
       "      <th>Cosine</th>\n",
       "      <th>sacrebleu_bleu</th>\n",
       "      <th>NLTK_bleu</th>\n",
       "      <th>chrf</th>\n",
       "      <th>sBURT</th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rouge2</th>\n",
       "      <th>rougeL</th>\n",
       "      <th>rougeLsum</th>\n",
       "      <th>ragas_bleu</th>\n",
       "      <th>ragas_fact</th>\n",
       "      <th>regas_sem_sim</th>\n",
       "      <th>regas_rogue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>53.0</td>\n",
       "      <td>0.328335</td>\n",
       "      <td>0.82</td>\n",
       "      <td>3.091681e-07</td>\n",
       "      <td>19.12</td>\n",
       "      <td>0.627521</td>\n",
       "      <td>0.106033</td>\n",
       "      <td>0.055046</td>\n",
       "      <td>0.087751</td>\n",
       "      <td>0.087751</td>\n",
       "      <td>0.166207</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.793754</td>\n",
       "      <td>0.087751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>48.0</td>\n",
       "      <td>0.123334</td>\n",
       "      <td>0.86</td>\n",
       "      <td>5.348766e-08</td>\n",
       "      <td>18.28</td>\n",
       "      <td>0.522151</td>\n",
       "      <td>0.084404</td>\n",
       "      <td>0.036832</td>\n",
       "      <td>0.055046</td>\n",
       "      <td>0.055046</td>\n",
       "      <td>0.216520</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.766267</td>\n",
       "      <td>0.058716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   similarity_score    Cosine sacrebleu_bleu     NLTK_bleu   chrf     sBURT  \\\n",
       "0              53.0  0.328335          0.82   3.091681e-07  19.12  0.627521   \n",
       "1              48.0  0.123334          0.86   5.348766e-08  18.28  0.522151   \n",
       "2               NaN       NaN            NaN           NaN    NaN       NaN   \n",
       "3               NaN       NaN            NaN           NaN    NaN       NaN   \n",
       "4               NaN       NaN            NaN           NaN    NaN       NaN   \n",
       "\n",
       "     rouge1    rouge2    rougeL  rougeLsum  ragas_bleu  ragas_fact  \\\n",
       "0  0.106033  0.055046  0.087751   0.087751    0.166207        0.30   \n",
       "1  0.084404  0.036832  0.055046   0.055046    0.216520        0.27   \n",
       "2       NaN       NaN       NaN        NaN         NaN         NaN   \n",
       "3       NaN       NaN       NaN        NaN         NaN         NaN   \n",
       "4       NaN       NaN       NaN        NaN         NaN         NaN   \n",
       "\n",
       "   regas_sem_sim  regas_rogue  \n",
       "0       0.793754     0.087751  \n",
       "1       0.766267     0.058716  \n",
       "2            NaN          NaN  \n",
       "3            NaN          NaN  \n",
       "4            NaN          NaN  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['similarity_score', 'Cosine', 'sacrebleu_bleu', 'NLTK_bleu', 'chrf',\n",
    "       'sBURT', 'rouge1', 'rouge2', 'rougeL', 'rougeLsum', 'ragas_bleu',\n",
    "       'ragas_fact', 'regas_sem_sim', 'regas_rogue']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e503e57a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
